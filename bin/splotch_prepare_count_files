#!/usr/bin/env python

from __future__ import absolute_import, division, print_function

import argparse
import logging
import os
import sys

import numpy
import pandas as pd
import scipy.io
import csv
import gzip
from pathlib import Path

import splotch

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)

def st_prepare_count_files(count_files, suffix, minimum_detection_rate):
  # Read count files
  logging.info('Reading %d count files'%(len(count_files)))
  frames = [pd.read_table(filename,header=0,index_col=0) for filename in count_files]

  prepare_count_files(count_files, frames, suffix, minimum_detection_rate)

def visium_prepare_count_files(spaceranger_dirs, suffix, minimum_detection_rate):
  # Assemble count matrix dataframe from components in output directories:
  frames = []
  count_files = []
  for srd in spaceranger_dirs:
    
    matrix_dir = os.path.join(srd, "outs/filtered_feature_bc_matrix/")
    mat = scipy.io.mmread(os.path.join(matrix_dir, "matrix.mtx.gz"))

    features_path = os.path.join(matrix_dir, "features.tsv.gz")
    feature_ids = [row[0] for row in csv.reader(gzip.open(features_path, "rt"), delimiter="\t")]

    barcodes_path = os.path.join(matrix_dir, "barcodes.tsv.gz")
    barcodes = [row[0] for row in csv.reader(gzip.open(barcodes_path, "rt"), delimiter="\t")]

    # Read spot position file
    if os.path.exists(os.path.join(srd, "outs/spatial/tissue_positions.csv")):
      positions_path = os.path.join(srd, "outs/spatial/tissue_positions.csv")  # Spaceranger >=2.0
      positions = pd.read_csv(positions_path, index_col=0, header=0)
    else:
      positions_path = os.path.join(srd, "outs/spatial/tissue_positions_list.csv") # Spaceranger <2.0
      positions = pd.read_csv(positions_path, index_col=0, header=None,
        names=["in_tissue", "array_row", "array_col", "pixel_row", "pixel_col"])

    positions_list = []
    for b in barcodes:
      xcoor = positions.loc[b,'array_col']
      ycoor = positions.loc[b,'array_row']
      positions_list.append('%d_%d' % (xcoor, ycoor))

    df = pd.DataFrame.sparse.from_spmatrix(mat, index=feature_ids, columns=positions_list)
    frames.append(df)
    count_files.append(os.path.join(srd, Path(srd).name))

  prepare_count_files(count_files, frames, suffix, minimum_detection_rate)
  
def prepare_count_files(count_files, frames, suffix='.unified.tsv', minimum_detection_rate=0.02):
  # Construct the multi index
  for filename,frame in zip(count_files,frames):
  	frame.columns = pd.MultiIndex.from_product([[filename],frame.columns],names=['Sample','Coordinate'])
  	frame.index.name = 'Gene'
  
  # concatenate counts
  result = pd.concat(frames,copy=False,axis=1,sort=True)
  logging.info('We have detected %d genes'%(result.shape[0]))
  # fill NaNs with zeros
  result = result.fillna(0).astype(int)
  
  # discard lowly expressed genes
  result = result[((result > 0).sum(axis=1)/float(result.shape[1])) > minimum_detection_rate]
  logging.info('We keep %d genes after discarding the lowly expressed genes (detected in less than %.2f%% of the ST spots)'%(result.shape[0],100.0*minimum_detection_rate))

  # print the median sequencing depth
  logging.info('The median sequencing depth across the ST spots is %d'%(numpy.median(result.sum(0))))
  
  # write the modified count files back to the disk
  for filename in result.columns.levels[0]:
    result[filename].to_csv(filename+suffix,sep='\t',index=True)

if __name__ == '__main__':

  parser = argparse.ArgumentParser(
    description='A script for preparing count files for Splotch')
  parser.add_argument('-c','--count_data',action='store',
                      dest='count_data',type=str,nargs='+',
                      required=True,help='list of read count filenames')
  parser.add_argument('-s','--suffix',action='store',
                      dest='suffix',type=str,required=False,
                      default='.unified.tsv',
                      help='suffix to be added to the output filenames (default is .unified.tsv)')
  parser.add_argument('-d','--minimum_detection_rate',action='store',
                      dest='minimum_detection_rate',type=float,required=False,
                      default=0.02,help='minimum detection rate (default is 0.02)')
  parser.add_argument('-v','--version',action='version',
                      version='%s %s'%(parser.prog,splotch.__version__))
  parser.add_argument('-V','--Visium',action='store_true',required=False,
                      help='output in Visium format (default is standard ST)')

  options = parser.parse_args()

  # check that the supplied read count files exist
  for filename in options.count_data:
    if not options.Visium and not os.path.isfile(filename):
      logging.critical('Count file %s does not exist!'%(filename))
      sys.exit(1)

    if options.Visium and not os.path.isdir(filename):
      logging.critical('Spaceranger count directory %s does not exist!'%(filename))
      sys.exit(1)

  # check that the minimum detection rate is valid
  if options.minimum_detection_rate < 0 or options.minimum_detection_rate > 1:
    logging.critical('Minimum detection rate should be between 0 and 1!')
    sys.exit(1)

  if not options.Visium:
    st_prepare_count_files(options.count_data, options.suffix, options.minimum_detection_rate)
  else:
    visium_prepare_count_files(options.count_data, options.suffix, options.minimum_detection_rate)

  sys.exit(0)
